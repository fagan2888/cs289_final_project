{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Initial Data Cleaning"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np, pandas as pd, os\n",
      "import initial_data_cleaning"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<p><font size = 4>1. Read in the data files</font></p>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#This variable should be either 11 or 12 for the year 2011 or 2012 respectively\n",
      "YEAR = 12\n",
      "MISSING_VALUE = 9999"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "accidents, vehicles, persons, safety_eq = initial_data_cleaning.get_tables(YEAR)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<p><font size=4>2. Filter out the PERSON records to retain only those records of cyclists who had an evident and non-incapacitating, incapacitating, or fatal injury</font></p>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cyclists = initial_data_cleaning.isolate_cyclists(persons)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<p><font size=4>3. Merge the GES VEHICLE data and ACCIDENT data with the PERSONS data for each injured cyclist, pruning duplicates</font></p>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cyclists_augmented = initial_data_cleaning.augment_cyclist_data(cyclists, accidents, vehicles)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<p><font size=4>4. Create new columns containing information about the driver which struck the cyclist</font></p>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "columns_to_add = [\"DRIVER_AGE\", \"DRIVER_SEX\", \"DRIVER_DRUGS\"]\n",
      "initial_data_cleaning.add_new_columns(cyclists_augmented, columns_to_add, [MISSING_VALUE])\n",
      "#Fill in the new columns with real data\n",
      "cyclists_augmented = cyclists_augmented.apply(initial_data_cleaning.fillNewColumns, axis = 1, args=(persons,))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<p><font size=4>5. Remove undesired or unhelpful (i.e. low-entropy) columns</font></p>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Output a csv, which I then use to get the column names in one column. Next to it I place a column called \"Include\" which contains\n",
      "#0 if I don't think the field is useful and 1 if I do think the field is useful. I saved that csv as \"fullyMerged_usefulVars.csv\"\n",
      "cyclists_augmented.to_csv(\"fullyMerged_20{}.csv\".format(YEAR))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "initial_data_cleaning.remove_unhelpful_columns(cyclists_augmented, \"fullyMerged_usefulVars.csv\", 10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "AttributeError",
       "evalue": "'module' object has no attribute 'remove_unhelpful_columns'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-30-5266b34182e8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0minitial_data_cleaning\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove_unhelpful_columns\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcyclists_augmented\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"fullyMerged_usefulVars.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;31mAttributeError\u001b[0m: 'module' object has no attribute 'remove_unhelpful_columns'"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cyclists_augmented.info()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<p><font size=4>6. Merge the GES Safety Equipment data with out dataframe</font></p>\n",
      "<p>Note: This step is performed after the cleaning in step 6 so that the safety information collected in both year 1 and year 2 can potentially be used in the model.</p>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "allButCategorySplit = initial_data_cleaning.add_safety_eq(cyclists_augmented, safety_eq)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<p><font size=4>8. Save the cleaned data</font></p>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "allButCategorySplit.to_csv(\"allButCategorySplit_20{}.csv\".format(YEAR))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<p><font size=4 color=\"blue\">Remaining:</font></p>\n",
      "\n",
      "<p><strong><u>Data Cleaning:</u></strong>\n",
      "    <ul><li>Go through all columns, and note the ones that are numeric vs categorical. Most will be categorical.</li>\n",
      "        <li>For the categorical columns which will actually be used in the classifier (for e.g., excluding things like the case number), convert each one into multiple columns, one per category.</li>\n",
      "        <li>Consider adding new columns which are dummy variables representing combinations of some of the categories in the categorical variables.</li>\n",
      "    </ul>\n",
      "</p>\n",
      "\n",
      "<p><strong><u>Modeling:</u></strong>\n",
      "    <ul><li>Use forward selection to build the logistic regression model?</li>\n",
      "        <li>Partition the data into a holdout and validation set (perhaps maintaining the ratio of serious and or fatal injuries to non-serious injuries). \n",
      "            <ol><li>Build the decision tree. Do an \"optimal\" pruning according to validation set accuracy.</li>\n",
      "                <li>Build a max depth tree under the idea of having at least 10 people per parameter in the final hybrid CART-Logistic Regression.</li>\n",
      "            </ol>\n",
      "        </li>\n",
      "        <li>Perform two(?) more logistic regression building efforts, this time with the decision tree dummy variables (from the optimally pruned tree in one, and from the max depth tree in the other) purposefully always included in the models.</li>\n",
      "    </ul>\n",
      "</p>\n",
      "\n",
      "<p><strong><u>Testing:</u></strong>\n",
      "    <ul><li>Prepare the data from the second year, in the same way the data for the first year was prepared.</li>\n",
      "        <li>Compute and store the prediction accuracies of the pure logit model, the \"optimally\" pruned tree, the \"max depth tree\", and the hybrid CART-Logit models using the second year of data.</li>\n",
      "        <li>Compute and store the sum of squared partial residuals for the pure logit model, the \"optimally\" pruned tree, the \"max depth tree\", and the hybrid CART-Logit models using their predictions for the second year of data.</li>\n",
      "    </ul>\n",
      "</p>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}