{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Initial Data Cleaning"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np, pandas as pd, os\n",
      "import initial_data_cleaning"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<p><font size = 4>1. Read in the data files</font></p>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#This variable should be either 11 or 12 for the year 2011 or 2012 respectively\n",
      "YEAR = 12\n",
      "MISSING_VALUE = 9999"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "accidents, vehicles, persons, safety_eq = initial_data_cleaning.get_tables(YEAR)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "C:\\Python27\\lib\\site-packages\\pandas\\io\\parsers.py:1070: DtypeWarning: Columns (34,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
        "  data = self._reader.read(nrows)\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<p><font size=4>2. Filter out the PERSON records to retain only those records of cyclists who had an evident and non-incapacitating, incapacitating, or fatal injury</font></p>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cyclists = initial_data_cleaning.isolate_cyclists(persons)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<p><font size=4>3. Merge the GES VEHICLE data and ACCIDENT data with the PERSONS data for each injured cyclist, pruning duplicates</font></p>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cyclists_augmented = initial_data_cleaning.augment_cyclist_data(cyclists, accidents, vehicles)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<p><font size=4>4. Create new columns containing information about the driver which struck the cyclist</font></p>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "columns_to_add = [\"DRIVER_AGE\", \"DRIVER_SEX\", \"DRIVER_DRUGS\"]\n",
      "initial_data_cleaning.add_new_columns(cyclists_augmented, columns_to_add, [MISSING_VALUE])\n",
      "#Fill in the new columns with real data\n",
      "cyclists_augmented = cyclists_augmented.apply(initial_data_cleaning.fillNewColumns, axis = 1, args=(persons,))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<p><font size=4>5. Remove undesired or unhelpful (i.e. low-entropy) columns</font></p>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Output a csv, which I then use to get the column names in one column. Next to it I place a column called \"Include\" which contains\n",
      "#0 if I don't think the field is useful and 1 if I do think the field is useful. I saved that csv as \"fullyMerged_usefulVars.csv\"\n",
      "cyclists_augmented.to_csv(\"fullyMerged_20{}.csv\".format(YEAR))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "initial_data_cleaning.removeUnhelpfulColumns(cyclists_augmented, \"fullyMerged_usefulVars.csv\", 10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cyclists_augmented.info()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Int64Index: 1919 entries, 0 to 1918\n",
        "Data columns (total 95 columns):\n",
        "CASENUM            1919 non-null int64\n",
        "PER_NO             1919 non-null int64\n",
        "SEX_IM             1919 non-null int64\n",
        "INJSEV_IM          1919 non-null int64\n",
        "PERALCH_IM         1919 non-null int64\n",
        "AGE_IM             1919 non-null int64\n",
        "VE_FORMS           1919 non-null int64\n",
        "WEIGHT             1919 non-null float64\n",
        "REGION             1919 non-null int64\n",
        "STRATUM            1919 non-null int64\n",
        "PJ                 1919 non-null int64\n",
        "PSU                1919 non-null int64\n",
        "PSUSTRAT           1919 non-null int64\n",
        "MONTH              1919 non-null int64\n",
        "HOUR               1919 non-null int64\n",
        "MINUTE             1919 non-null int64\n",
        "AGE                1919 non-null int64\n",
        "SEX                1919 non-null int64\n",
        "INJ_SEV            1919 non-null int64\n",
        "DRINKING           1919 non-null int64\n",
        "DRUGS              1919 non-null int64\n",
        "HOSPITAL           1919 non-null int64\n",
        "P_SF1              1919 non-null int64\n",
        "LOCATION           1919 non-null int64\n",
        "HITRUN_IM          1919 non-null int64\n",
        "BDYTYP_IM          1919 non-null int64\n",
        "IMPACT1_IM         1919 non-null int64\n",
        "PCRASH1_IM         1919 non-null int64\n",
        "V_ALCH_IM          1919 non-null int64\n",
        "NUMOCCS            1919 non-null int64\n",
        "HIT_RUN            1919 non-null int64\n",
        "BODY_TYP_vehDup    1919 non-null int64\n",
        "TOW_VEH_vehDup     1919 non-null int64\n",
        "J_KNIFE            1919 non-null int64\n",
        "GVWR               1919 non-null int64\n",
        "V_CONFIG           1919 non-null int64\n",
        "CARGO_BT           1919 non-null int64\n",
        "BUS_USE            1919 non-null int64\n",
        "SPEC_USE_vehDup    1919 non-null int64\n",
        "EMER_USE_vehDup    1919 non-null int64\n",
        "TRAV_SP            1919 non-null int64\n",
        "IMPACT1_vehDup     1919 non-null int64\n",
        "VEH_SC1            1919 non-null int64\n",
        "VEH_SC2            1919 non-null int64\n",
        "VEH_ALCH           1919 non-null int64\n",
        "SPEEDREL           1919 non-null int64\n",
        "DR_SF1             1919 non-null int64\n",
        "DR_SF2             1919 non-null int64\n",
        "DR_SF3             1919 non-null int64\n",
        "DR_SF4             1919 non-null int64\n",
        "VTRAFWAY           1919 non-null int64\n",
        "VNUM_LAN           1919 non-null int64\n",
        "VSPD_LIM           1919 non-null int64\n",
        "VALIGN             1919 non-null int64\n",
        "VPROFILE           1919 non-null int64\n",
        "VSURCOND           1919 non-null int64\n",
        "VTRAFCON           1919 non-null int64\n",
        "VTCONT_F           1919 non-null int64\n",
        "P_CRASH1           1919 non-null int64\n",
        "P_CRASH2           1919 non-null int64\n",
        "P_CRASH3           1919 non-null int64\n",
        "PCRASH4            1919 non-null int64\n",
        "PCRASH5            1919 non-null int64\n",
        "ACC_TYPE           1919 non-null int64\n",
        "WKDY_IM            1919 non-null int64\n",
        "HOUR_IM            1919 non-null int64\n",
        "MINUTE_IM          1919 non-null int64\n",
        "RELJCT1_IM         1919 non-null int64\n",
        "RELJCT2_IM         1919 non-null int64\n",
        "LGTCON_IM          1919 non-null int64\n",
        "WEATHR_IM          1919 non-null int64\n",
        "ALCHL_IM           1919 non-null int64\n",
        "LAND_USE           1919 non-null int64\n",
        "VE_TOTAL           1919 non-null int64\n",
        "PEDS               1919 non-null int64\n",
        "PERMVIT            1919 non-null int64\n",
        "PERNOTMVIT         1919 non-null int64\n",
        "DAY_WEEK           1919 non-null int64\n",
        "ALCOHOL            1919 non-null int64\n",
        "RELJCT1            1919 non-null int64\n",
        "RELJCT2            1919 non-null int64\n",
        "TYP_INT            1919 non-null int64\n",
        "WRK_ZONE           1919 non-null int64\n",
        "REL_ROAD           1919 non-null int64\n",
        "LGT_COND           1919 non-null int64\n",
        "WEATHER1           1919 non-null int64\n",
        "WEATHER2           1919 non-null int64\n",
        "WEATHER            1919 non-null int64\n",
        "INT_HWY            1919 non-null int64\n",
        "CF1                1919 non-null int64\n",
        "CF2                1919 non-null int64\n",
        "CF3                1919 non-null int64\n",
        "DRIVER_AGE         1919 non-null int64\n",
        "DRIVER_SEX         1919 non-null int64\n",
        "DRIVER_DRUGS       1919 non-null int64\n",
        "dtypes: float64(1), int64(94)"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<p><font size=4>6. Merge the GES Safety Equipment data with out dataframe</font></p>\n",
      "<p>Note: This step is performed after the cleaning in step 6 so that the safety information collected in both year 1 and year 2 can potentially be used in the model.</p>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "allButCategorySplit = initial_data_cleaning.addSafetyEQ(cyclists_augmented, safety_eq)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<p><font size=4>8. Save the cleaned data</font></p>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "allButCategorySplit.to_csv(\"allButCategorySplit_20{}.csv\".format(YEAR))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<p><font size=4 color=\"blue\">Remaining:</font></p>\n",
      "\n",
      "<p><strong><u>Data Cleaning:</u></strong>\n",
      "    <ul><li>Go through all columns, and note the ones that are numeric vs categorical. Most will be categorical.</li>\n",
      "        <li>For the categorical columns which will actually be used in the classifier (for e.g., excluding things like the case number), convert each one into multiple columns, one per category.</li>\n",
      "        <li>Consider adding new columns which are dummy variables representing combinations of some of the categories in the categorical variables.</li>\n",
      "    </ul>\n",
      "</p>\n",
      "\n",
      "<p><strong><u>Modeling:</u></strong>\n",
      "    <ul><li>Use forward selection to build the logistic regression model?</li>\n",
      "        <li>Partition the data into a holdout and validation set (perhaps maintaining the ratio of serious and or fatal injuries to non-serious injuries). \n",
      "            <ol><li>Build the decision tree. Do an \"optimal\" pruning according to validation set accuracy.</li>\n",
      "                <li>Build a max depth tree under the idea of having at least 10 people per parameter in the final hybrid CART-Logistic Regression.</li>\n",
      "            </ol>\n",
      "        </li>\n",
      "        <li>Perform two(?) more logistic regression building efforts, this time with the decision tree dummy variables (from the optimally pruned tree in one, and from the max depth tree in the other) purposefully always included in the models.</li>\n",
      "    </ul>\n",
      "</p>\n",
      "\n",
      "<p><strong><u>Testing:</u></strong>\n",
      "    <ul><li>Prepare the data from the second year, in the same way the data for the first year was prepared.</li>\n",
      "        <li>Compute and store the prediction accuracies of the pure logit model, the \"optimally\" pruned tree, the \"max depth tree\", and the hybrid CART-Logit models using the second year of data.</li>\n",
      "        <li>Compute and store the sum of squared partial residuals for the pure logit model, the \"optimally\" pruned tree, the \"max depth tree\", and the hybrid CART-Logit models using their predictions for the second year of data.</li>\n",
      "    </ul>\n",
      "</p>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}