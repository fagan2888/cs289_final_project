{
 "metadata": {
  "name": "reduced_error_pruning.ipynb"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np, pandas as pd\n",
      "import treepredict, cPickle\n",
      "from copy import deepcopy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Create the functions to do the pruning of the trees"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_results(node):\n",
      "    \"\"\"node = a particular decisionNode from a decision tree.\n",
      "    ==========\n",
      "    Returns a dictionary which has labels as keys, and the number of training observations with said label that made it to this \n",
      "    node.\"\"\"\n",
      "    if node.results is not None: #Check if the node is a leaf.\n",
      "        return node.results #If the node is a leaf, then just return its results\n",
      "    else: #If the node is not a leaf, recursively combine the results from its branches.\n",
      "        tbr = get_results(node.tb) #get the results from the true branch\n",
      "        fbr = get_results(node.fb) #get the results from the false branch\n",
      "    \n",
      "    new_results = deepcopy(tbr) #make a deep copy of the results from the true branch\n",
      "    for key in fbr: #Iterate through the keys in the false branch\n",
      "        if key not in new_results: #Check whether or not the key is in the deep copy of the true branch\n",
      "            new_results[key] = fbr[key] #If it is not, add the key to the deep copy, and make its value equal to the value in fbr\n",
      "        else: #If the key is in the deep copy of the true branch, add the false branch's count to the value in the deep copy\n",
      "            new_results[key] = fbr[key] + new_results[key]\n",
      "    return new_results #return the merged results from the false and true branches"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def count_errors(node, testSet, res):\n",
      "    \"\"\"node = a particular decisionNode from within a given tree.\n",
      "    testSet = the pandas dataframe of testing observations that would make it to this node\n",
      "    res = the name of the column of results within the testSet dataframe.\n",
      "    ==========\n",
      "    Treats the node as a leaf and returns the number of testSet observations that would be misclassified on the basis of\n",
      "    having made it to this node.\"\"\"\n",
      "    training_results = get_results(node) #Get a dictionary of labels and counts for the *training* data which made it to this node\n",
      "    leaf_label = None #Initialize a label for this leaf\n",
      "    majority_count = 0 #Initialize a variable to track the number of observations for the label with the most observations\n",
      "    #Note that the steps below do not handle ties of the majority count in a nice way.\n",
      "    for label, count in training_results.items(): #iterate through each pair of labels and counts from the training set\n",
      "        if count > majority_count: #find the label with the highest count\n",
      "            leaf_label = label #the label for the leaf is the label with the highest count\n",
      "            majority_count = count #keep track of the count for the leaf_label\n",
      "    \n",
      "    wrong_labels = testSet[res].unique().tolist() #initialize wrong_labels to be all labels in the testSet\n",
      "    if leaf_label in wrong_labels: #If the leaf label is in the list of labels for the part of the test set that got to this node\n",
      "        wrong_labels.remove(leaf_label) #remove the leaf_label so that all which remains are incorrect labels\n",
      "    \n",
      "    wrong_count = 0 #Initialize a count of how many testSet observations will be classified incorrectly\n",
      "    testCounts = testSet.groupby(res).size() #Get a series of the testSet labels and how many observations pertain to each label\n",
      "    for label in wrong_labels: #Iterate over all the labels not equal to the leaf_label\n",
      "        wrong_count += testCounts[label] #Sum up all of the observations with a label not equal to the leaf_label\n",
      "    return wrong_count"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def deep_count_errors(node, testSet, res):\n",
      "    \"\"\"node = a particular decisionNode from within a given tree.\n",
      "    testSet = the pandas dataframe of testing observations that would make it to this node\n",
      "    res = the name of the column of results within the testSet dataframe.\n",
      "    ==========\n",
      "    Distinguishes between branch nodes and leaf nodes. For leaf nodes, it returns the number of testSet observations that would be \n",
      "    misclassified on the basis of having made it to this node. For branch nodes, it returns the total number of observations that\n",
      "    would be misclassified after making it to this node and being further classified by its descendant leaf nodes.\"\"\"\n",
      "    if node.results is not None: #Check if this node is a leaf node\n",
      "        return count_errors(node, testSet, res) #If so, return the test set classification errors made by this node.\n",
      "    else:\n",
      "        tbSet = testSet[testSet[node.col] >= node.value] #find which test observations belong to this tree's true branch\n",
      "        fbSet = testSet[testSet[node.col] < node.value] #find which test observations belong to this tree's false branch\n",
      "        \n",
      "        if node.tb.results is None: #Check if the true branch is a branch node\n",
      "            #If so, get the count of all misclassifications made by this branch's descendent leaf nodes on the test observations\n",
      "            term1 = deep_count_errors(node.tb, tbSet, res)\n",
      "        else: #If the true branch is a leaf node, return the count of all test set classification errors made by the leaf.\n",
      "            term1 = count_errors(node.tb, tbSet,res)\n",
      "        if node.fb.results is None: #Check if the false branch is a branch node\n",
      "            #If so, get the count of all misclassifications made by this branch's descendent leaf nodes on the test observations\n",
      "            term2 = deep_count_errors(node.fb, fbSet, res)\n",
      "        else: #If the false branch is a leaf node, return the count of all test set classification errors made by the leaf.\n",
      "            term2 = count_errors(node.fb, fbSet, res) \n",
      "        return term1 + term2 #Sum the classification errors made by this nodes descendant leaves."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def prune(tree, testSet, res, technique):\n",
      "    \"\"\"tree = a decision tree to be pruned\n",
      "    testSet = a pandas dataframe of observations and labels that were not used to train the tree\n",
      "    res = the column name of the results column\n",
      "    technique = a string indicating what pruning technique to use. Options include: \"reduced_error\".\n",
      "    ==========\n",
      "    Returns a decision tree that has been pruned according to a given pruning technique.\"\"\"\n",
      "    if technique == \"reduced_error\":\n",
      "        tbSet = testSet[testSet[tree.col] >= tree.value] #find which test observations belong to this tree's true branch\n",
      "        fbSet = testSet[testSet[tree.col] < tree.value] #find which test observations belong to this tree's false branch\n",
      "        \n",
      "        if tree.tb.results is None: #Check if the true branch of this sub-tree is a leaf\n",
      "            ptb = prune(tree.tb, tbSet, res, technique) #If not, recursively travel down the true branch and prune it.\n",
      "        else:\n",
      "            ptb = tree.tb #If the true branch is a leaf, then the true branch has--in essence--already been pruned.\n",
      "        if tree.fb.results is None: #Check if the false branch of this sub-tree is a leaf\n",
      "            pfb = prune(tree.fb, fbSet, res, technique) #If not, recursively travel down the false branch and prune it.\n",
      "        else:\n",
      "            pfb = tree.fb #If the false branch is a leaf, then the false branch has--in essence--already been pruned.\n",
      "        \n",
      "        #Sum the number of misclassifications of the test data at each of the leaves of this node\n",
      "        wrong_in_leaves = deep_count_errors(ptb, tbSet, res) + deep_count_errors(pfb, fbSet, res)\n",
      "            \n",
      "        #Count the number of misclassificationsof the test data that would occur if this node were treated as a leaf\n",
      "        wrong_at_node = count_errors(tree, testSet, res)\n",
      "        \n",
      "        #Assess whether or not treating the node as a leaf improves the accuracy on the test set\n",
      "        if wrong_at_node <= wrong_in_leaves: \n",
      "            #NOTE:The following line of code seems slightly redundant since count_errors(tree, testSet, res) had to call \n",
      "            #get_results(tree). I should set up some way to save the output of that function call instead of calling it twice.\n",
      "            return decisionNode(results = get_results(tree)) #If so, return a decisionNode where the node is a leaf\n",
      "        else:\n",
      "            #If not, return a decisionNode where the node splits on the same column and value as before, but the \n",
      "            #true and false branches are the pruned-versions of the original true and false branches. See above for\n",
      "            #definition of ptb and pfb\n",
      "            return decisionNode(col = tree.col, value = tree.value, tb = ptb, fb = pfb)  "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Testing the prune function within treepredict.py"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open(\"trees/unpruned_NaiveTree_trainingSet.pkl\", \"rb\") as f:\n",
      "    unpruned_tSet_tree = cPickle.load(f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vSet = pd.read_pickle(\"dataframes/validationSet_DF_naiveTree.pkl\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "prune_test1 = treepredict.prune(unpruned_tSet_tree, vSet, \"SER_INJ\", \"reduced_error\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "treepredict.printtree(prune_test1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "C(PCRASH1_IM)[T.1]:1? \n",
        "T-> C(ALCHL_IM)[T.2]:1? \n",
        " T-> C(VPROFILE, Treatment(9999))[T.1]:1? \n",
        "  T-> NUMOCCS:4? \n",
        "   T-> {0: 17, 1: 1}\n",
        "   F-> C(VTCONT_F, Treatment(9999))[T.3]:1? \n",
        "    T-> MSAFEQMT1:1? \n",
        "     T-> C(DRUGS, Treatment(9999))[T.0]:1? \n",
        "      T-> C(LOCATION, Treatment(9999))[T.2]:1? \n",
        "       T-> C(MONTH)[T.2]:1? \n",
        "        T-> {1: 1}\n",
        "        F-> {0: 1}\n",
        "       F-> {0: 34}\n",
        "      F-> {0: 4, 1: 3}\n",
        "     F-> {0: 27, 1: 13}\n",
        "    F-> {0: 143, 1: 81}\n",
        "  F-> C(IMPACT2_vehDup, Treatment(9999))[T.4]:1? \n",
        "   T-> {1: 2}\n",
        "   F-> DRIVER_AGE:68? \n",
        "    T-> {0: 18}\n",
        "    F-> C(IMPACT1_IM)[T.12]:1? \n",
        "     T-> {0: 52, 1: 16}\n",
        "     F-> C(TYP_INT, Treatment(9999))[T.1]:1? \n",
        "      T-> C(WKDY_IM)[T.7]:1? \n",
        "       T-> {0: 1, 1: 2}\n",
        "       F-> AGE_IM:30? \n",
        "        T-> AGE_IM:49? \n",
        "         T-> {0: 3}\n",
        "         F-> {1: 2}\n",
        "        F-> {0: 16}\n",
        "      F-> {0: 24}\n",
        " F-> AGE_IM:51? \n",
        "  T-> {1: 7}\n",
        "  F-> C(LGTCON_IM)[T.2]:1? \n",
        "   T-> {1: 4}\n",
        "   F-> C(SPEEDREL, Treatment(9999))[T.0]:1? \n",
        "    T-> C(LGTCON_IM)[T.3]:1? \n",
        "     T-> {1: 4}\n",
        "     F-> {0: 6, 1: 2}\n",
        "    F-> {0: 4}\n",
        "F-> {0: 557, 1: 97}\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "unpruned_acc = treepredict.testAccuracy(vSet, unpruned_tSet_tree, [0,1], \"SER_INJ\")\n",
      "unpruned_feats = treepredict.searchFeats(unpruned_tSet_tree) #relevant features in unpruned decision tree\n",
      "print \"The original unpruned tree had an accuracy of {} and used {} features.\".format(unpruned_acc, len(unpruned_feats))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The original unpruned tree had an accuracy of 0.656140350877 and used 101 features.\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pruned_acc = treepredict.testAccuracy(vSet, prune_test1, [0,1], \"SER_INJ\")\n",
      "pruned_feats = treepredict.searchFeats(prune_test1) #relevant features in the pruned decision tree\n",
      "print \"The pruned tree had an accuracy of {} and used {} features.\".format(pruned_acc, len(pruned_feats))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The pruned tree had an accuracy of 0.789473684211 and used 18 features.\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pruned_feats"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "{'AGE_IM',\n",
        " 'C(ALCHL_IM)[T.2]',\n",
        " 'C(DRUGS, Treatment(9999))[T.0]',\n",
        " 'C(IMPACT1_IM)[T.12]',\n",
        " 'C(IMPACT2_vehDup, Treatment(9999))[T.4]',\n",
        " 'C(LGTCON_IM)[T.2]',\n",
        " 'C(LGTCON_IM)[T.3]',\n",
        " 'C(LOCATION, Treatment(9999))[T.2]',\n",
        " 'C(MONTH)[T.2]',\n",
        " 'C(PCRASH1_IM)[T.1]',\n",
        " 'C(SPEEDREL, Treatment(9999))[T.0]',\n",
        " 'C(TYP_INT, Treatment(9999))[T.1]',\n",
        " 'C(VPROFILE, Treatment(9999))[T.1]',\n",
        " 'C(VTCONT_F, Treatment(9999))[T.3]',\n",
        " 'C(WKDY_IM)[T.7]',\n",
        " 'DRIVER_AGE',\n",
        " 'MSAFEQMT1',\n",
        " 'NUMOCCS'}"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open(\"trees/pruned_NaiveTree_trainingSet.pkl\", \"wb\") as f:\n",
      "    cPickle.dump(prune_test1, f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Test the countNodes and fetchNodes functions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "treepredict.countNodes(prune_test1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "21"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "treepredict.countNodes(unpruned_tSet_tree)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "194"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The following fetchNodes() function was added to treepredict.py to retrieve nodes from a tree"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def fetchNodes(tree):\n",
      "    \"\"\"Returns a list containing one list per node of the conditions, in order, that need to be met to end up in a particular\n",
      "    node.\"\"\"\n",
      "    if tree.results is None: #Check if the node is a branch\n",
      "        condItems = {} #Initialize a container for the node conditions from lower branches\n",
      "        v = [\"true\", \"false\"] #\"Veracity values\"\n",
      "        for branch, veracity in [(tree.tb, v[0]), (tree.fb, v[1])]: #iterate over this node's true and false child nodes\n",
      "            if fetchNodes(branch) == []: #Check if the child node is actually a leaf. If so,\n",
      "                condItems[veracity] = [[(tree.col, tree.value, veracity)]] #Initialize the condition needed to reach that leaf\n",
      "            else:\n",
      "                condItems[veracity] = [] #If the child is not a leaf, initialize an empty list to contain its updated conditions\n",
      "                for item in fetchNodes(branch): #Iterate over each set of node conditions that stem from this branch\n",
      "                    new_descriptor = deepcopy(item) #make a deep copy of the list of node conditions from the lower level nodes\n",
      "                    #insert this node's condition at the beginning of each of the node conditions from the lower levels\n",
      "                    new_descriptor.insert(0, (tree.col, tree.value, veracity)) \n",
      "                    condItems[veracity].append(new_descriptor) #append the updated set of node conditions to the branches items\n",
      "        node_conditions = deepcopy(condItems[v[0]]) #Initialize the complete list of node conditions that stem from this node\n",
      "        node_conditions.extend(deepcopy(condItems[v[1]])) #Add the node conditions from the second branch of this node\n",
      "        return node_conditions #Send the full set of node conditions from this node up to the higher nodes.\n",
      "    else: #If the node is a leaf, return an empty list\n",
      "        return []"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reload(treepredict)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "<module 'treepredict' from 'treepredict.pyc'>"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_nodes = treepredict.fetchNodes(prune_test1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(test_nodes)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "21"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "line_sep = \"=\"*10\n",
      "count = 0\n",
      "for i in test_nodes:\n",
      "    print line_sep\n",
      "    print \"Node {}\".format(count)\n",
      "    for j in i:\n",
      "        print j\n",
      "    count += 1\n",
      "    print line_sep"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "==========\n",
        "Node 0\n",
        "('C(PCRASH1_IM)[T.1]', 1, 'true')\n",
        "('C(ALCHL_IM)[T.2]', 1, 'true')\n",
        "('C(VPROFILE, Treatment(9999))[T.1]', 1, 'true')\n",
        "('NUMOCCS', 4, 'true')\n",
        "{0: 17, 1: 1}\n",
        "==========\n",
        "==========\n",
        "Node 1\n",
        "('C(PCRASH1_IM)[T.1]', 1, 'true')\n",
        "('C(ALCHL_IM)[T.2]', 1, 'true')\n",
        "('C(VPROFILE, Treatment(9999))[T.1]', 1, 'true')\n",
        "('NUMOCCS', 4, 'false')\n",
        "('C(VTCONT_F, Treatment(9999))[T.3]', 1, 'true')\n",
        "('MSAFEQMT1', 1, 'true')\n",
        "('C(DRUGS, Treatment(9999))[T.0]', 1, 'true')\n",
        "('C(LOCATION, Treatment(9999))[T.2]', 1, 'true')\n",
        "('C(MONTH)[T.2]', 1, 'true')\n",
        "{1: 1}\n",
        "==========\n",
        "==========\n",
        "Node 2\n",
        "('C(PCRASH1_IM)[T.1]', 1, 'true')\n",
        "('C(ALCHL_IM)[T.2]', 1, 'true')\n",
        "('C(VPROFILE, Treatment(9999))[T.1]', 1, 'true')\n",
        "('NUMOCCS', 4, 'false')\n",
        "('C(VTCONT_F, Treatment(9999))[T.3]', 1, 'true')\n",
        "('MSAFEQMT1', 1, 'true')\n",
        "('C(DRUGS, Treatment(9999))[T.0]', 1, 'true')\n",
        "('C(LOCATION, Treatment(9999))[T.2]', 1, 'true')\n",
        "('C(MONTH)[T.2]', 1, 'false')\n",
        "{0: 1}\n",
        "==========\n",
        "==========\n",
        "Node 3\n",
        "('C(PCRASH1_IM)[T.1]', 1, 'true')\n",
        "('C(ALCHL_IM)[T.2]', 1, 'true')\n",
        "('C(VPROFILE, Treatment(9999))[T.1]', 1, 'true')\n",
        "('NUMOCCS', 4, 'false')\n",
        "('C(VTCONT_F, Treatment(9999))[T.3]', 1, 'true')\n",
        "('MSAFEQMT1', 1, 'true')\n",
        "('C(DRUGS, Treatment(9999))[T.0]', 1, 'true')\n",
        "('C(LOCATION, Treatment(9999))[T.2]', 1, 'false')\n",
        "{0: 34}\n",
        "==========\n",
        "==========\n",
        "Node 4\n",
        "('C(PCRASH1_IM)[T.1]', 1, 'true')\n",
        "('C(ALCHL_IM)[T.2]', 1, 'true')\n",
        "('C(VPROFILE, Treatment(9999))[T.1]', 1, 'true')\n",
        "('NUMOCCS', 4, 'false')\n",
        "('C(VTCONT_F, Treatment(9999))[T.3]', 1, 'true')\n",
        "('MSAFEQMT1', 1, 'true')\n",
        "('C(DRUGS, Treatment(9999))[T.0]', 1, 'false')\n",
        "{0: 4, 1: 3}\n",
        "==========\n",
        "==========\n",
        "Node 5\n",
        "('C(PCRASH1_IM)[T.1]', 1, 'true')\n",
        "('C(ALCHL_IM)[T.2]', 1, 'true')\n",
        "('C(VPROFILE, Treatment(9999))[T.1]', 1, 'true')\n",
        "('NUMOCCS', 4, 'false')\n",
        "('C(VTCONT_F, Treatment(9999))[T.3]', 1, 'true')\n",
        "('MSAFEQMT1', 1, 'false')\n",
        "{0: 27, 1: 13}\n",
        "==========\n",
        "==========\n",
        "Node 6\n",
        "('C(PCRASH1_IM)[T.1]', 1, 'true')\n",
        "('C(ALCHL_IM)[T.2]', 1, 'true')\n",
        "('C(VPROFILE, Treatment(9999))[T.1]', 1, 'true')\n",
        "('NUMOCCS', 4, 'false')\n",
        "('C(VTCONT_F, Treatment(9999))[T.3]', 1, 'false')\n",
        "{0: 143, 1: 81}\n",
        "==========\n",
        "==========\n",
        "Node 7\n",
        "('C(PCRASH1_IM)[T.1]', 1, 'true')\n",
        "('C(ALCHL_IM)[T.2]', 1, 'true')\n",
        "('C(VPROFILE, Treatment(9999))[T.1]', 1, 'false')\n",
        "('C(IMPACT2_vehDup, Treatment(9999))[T.4]', 1, 'true')\n",
        "{1: 2}\n",
        "==========\n",
        "==========\n",
        "Node 8\n",
        "('C(PCRASH1_IM)[T.1]', 1, 'true')\n",
        "('C(ALCHL_IM)[T.2]', 1, 'true')\n",
        "('C(VPROFILE, Treatment(9999))[T.1]', 1, 'false')\n",
        "('C(IMPACT2_vehDup, Treatment(9999))[T.4]', 1, 'false')\n",
        "('DRIVER_AGE', 68, 'true')\n",
        "{0: 18}\n",
        "==========\n",
        "==========\n",
        "Node 9\n",
        "('C(PCRASH1_IM)[T.1]', 1, 'true')\n",
        "('C(ALCHL_IM)[T.2]', 1, 'true')\n",
        "('C(VPROFILE, Treatment(9999))[T.1]', 1, 'false')\n",
        "('C(IMPACT2_vehDup, Treatment(9999))[T.4]', 1, 'false')\n",
        "('DRIVER_AGE', 68, 'false')\n",
        "('C(IMPACT1_IM)[T.12]', 1, 'true')\n",
        "{0: 52, 1: 16}\n",
        "==========\n",
        "==========\n",
        "Node 10\n",
        "('C(PCRASH1_IM)[T.1]', 1, 'true')\n",
        "('C(ALCHL_IM)[T.2]', 1, 'true')\n",
        "('C(VPROFILE, Treatment(9999))[T.1]', 1, 'false')\n",
        "('C(IMPACT2_vehDup, Treatment(9999))[T.4]', 1, 'false')\n",
        "('DRIVER_AGE', 68, 'false')\n",
        "('C(IMPACT1_IM)[T.12]', 1, 'false')\n",
        "('C(TYP_INT, Treatment(9999))[T.1]', 1, 'true')\n",
        "('C(WKDY_IM)[T.7]', 1, 'true')\n",
        "{0: 1, 1: 2}\n",
        "==========\n",
        "==========\n",
        "Node 11\n",
        "('C(PCRASH1_IM)[T.1]', 1, 'true')\n",
        "('C(ALCHL_IM)[T.2]', 1, 'true')\n",
        "('C(VPROFILE, Treatment(9999))[T.1]', 1, 'false')\n",
        "('C(IMPACT2_vehDup, Treatment(9999))[T.4]', 1, 'false')\n",
        "('DRIVER_AGE', 68, 'false')\n",
        "('C(IMPACT1_IM)[T.12]', 1, 'false')\n",
        "('C(TYP_INT, Treatment(9999))[T.1]', 1, 'true')\n",
        "('C(WKDY_IM)[T.7]', 1, 'false')\n",
        "('AGE_IM', 30, 'true')\n",
        "('AGE_IM', 49, 'true')\n",
        "{0: 3}\n",
        "==========\n",
        "==========\n",
        "Node 12\n",
        "('C(PCRASH1_IM)[T.1]', 1, 'true')\n",
        "('C(ALCHL_IM)[T.2]', 1, 'true')\n",
        "('C(VPROFILE, Treatment(9999))[T.1]', 1, 'false')\n",
        "('C(IMPACT2_vehDup, Treatment(9999))[T.4]', 1, 'false')\n",
        "('DRIVER_AGE', 68, 'false')\n",
        "('C(IMPACT1_IM)[T.12]', 1, 'false')\n",
        "('C(TYP_INT, Treatment(9999))[T.1]', 1, 'true')\n",
        "('C(WKDY_IM)[T.7]', 1, 'false')\n",
        "('AGE_IM', 30, 'true')\n",
        "('AGE_IM', 49, 'false')\n",
        "{1: 2}\n",
        "==========\n",
        "==========\n",
        "Node 13\n",
        "('C(PCRASH1_IM)[T.1]', 1, 'true')\n",
        "('C(ALCHL_IM)[T.2]', 1, 'true')\n",
        "('C(VPROFILE, Treatment(9999))[T.1]', 1, 'false')\n",
        "('C(IMPACT2_vehDup, Treatment(9999))[T.4]', 1, 'false')\n",
        "('DRIVER_AGE', 68, 'false')\n",
        "('C(IMPACT1_IM)[T.12]', 1, 'false')\n",
        "('C(TYP_INT, Treatment(9999))[T.1]', 1, 'true')\n",
        "('C(WKDY_IM)[T.7]', 1, 'false')\n",
        "('AGE_IM', 30, 'false')\n",
        "{0: 16}\n",
        "==========\n",
        "==========\n",
        "Node 14\n",
        "('C(PCRASH1_IM)[T.1]', 1, 'true')\n",
        "('C(ALCHL_IM)[T.2]', 1, 'true')\n",
        "('C(VPROFILE, Treatment(9999))[T.1]', 1, 'false')\n",
        "('C(IMPACT2_vehDup, Treatment(9999))[T.4]', 1, 'false')\n",
        "('DRIVER_AGE', 68, 'false')\n",
        "('C(IMPACT1_IM)[T.12]', 1, 'false')\n",
        "('C(TYP_INT, Treatment(9999))[T.1]', 1, 'false')\n",
        "{0: 24}\n",
        "==========\n",
        "==========\n",
        "Node 15\n",
        "('C(PCRASH1_IM)[T.1]', 1, 'true')\n",
        "('C(ALCHL_IM)[T.2]', 1, 'false')\n",
        "('AGE_IM', 51, 'true')\n",
        "{1: 7}\n",
        "==========\n",
        "==========\n",
        "Node 16\n",
        "('C(PCRASH1_IM)[T.1]', 1, 'true')\n",
        "('C(ALCHL_IM)[T.2]', 1, 'false')\n",
        "('AGE_IM', 51, 'false')\n",
        "('C(LGTCON_IM)[T.2]', 1, 'true')\n",
        "{1: 4}\n",
        "==========\n",
        "==========\n",
        "Node 17\n",
        "('C(PCRASH1_IM)[T.1]', 1, 'true')\n",
        "('C(ALCHL_IM)[T.2]', 1, 'false')\n",
        "('AGE_IM', 51, 'false')\n",
        "('C(LGTCON_IM)[T.2]', 1, 'false')\n",
        "('C(SPEEDREL, Treatment(9999))[T.0]', 1, 'true')\n",
        "('C(LGTCON_IM)[T.3]', 1, 'true')\n",
        "{1: 4}\n",
        "==========\n",
        "==========\n",
        "Node 18\n",
        "('C(PCRASH1_IM)[T.1]', 1, 'true')\n",
        "('C(ALCHL_IM)[T.2]', 1, 'false')\n",
        "('AGE_IM', 51, 'false')\n",
        "('C(LGTCON_IM)[T.2]', 1, 'false')\n",
        "('C(SPEEDREL, Treatment(9999))[T.0]', 1, 'true')\n",
        "('C(LGTCON_IM)[T.3]', 1, 'false')\n",
        "{0: 6, 1: 2}\n",
        "==========\n",
        "==========\n",
        "Node 19\n",
        "('C(PCRASH1_IM)[T.1]', 1, 'true')\n",
        "('C(ALCHL_IM)[T.2]', 1, 'false')\n",
        "('AGE_IM', 51, 'false')\n",
        "('C(LGTCON_IM)[T.2]', 1, 'false')\n",
        "('C(SPEEDREL, Treatment(9999))[T.0]', 1, 'false')\n",
        "{0: 4}\n",
        "==========\n",
        "==========\n",
        "Node 20\n",
        "('C(PCRASH1_IM)[T.1]', 1, 'false')\n",
        "{0: 557, 1: 97}\n",
        "==========\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    }
   ],
   "metadata": {}
  }
 ]
}