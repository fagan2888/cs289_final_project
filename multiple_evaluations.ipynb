{
 "metadata": {
  "name": "multiple_evaluations.ipynb"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Multiple Evaluations:<br> Decision Tree, Binary Logit Model, and Hybrid CART-Logit Model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd, statsmodels.formula.api as smf, hybrid_logit as hl, matplotlib.pyplot as plt\n",
      "import treepredict, cPickle\n",
      "from copy import deepcopy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "orig_design = pd.read_pickle(\"dataframes/design_DF_4Tree.pkl\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"There are {} records in the original design matrix\".format(len(orig_design))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "'There are 1427 records in the original design matrix'"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"There are {} columns in the original design matrix\".format(len(orig_design.columns))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "'There are 331 columns in the original design matrix'"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def split_data(df, pruning_proportion):\n",
      "    \"\"\"df = the dataframe that you want to split into a training and pruning set\n",
      "    pruning_proportion = the decimal representing the percentage of rows of df to be set aside as the pruning set\n",
      "    ==========\n",
      "    Returns two dataframes, the training set and the pruning set.\"\"\"\n",
      "    \n",
      "    assert isinstance(df, pd.DataFrame) #Make sure df is a pandas dataframe\n",
      "    assert pruning_proportion <= 1 and pruning_proportion >= 0 #Make sure the pruning_proportion is between 0 and 1\n",
      "    \n",
      "    rows = df.index.tolist() #Get a list of the rows in the dataframe\n",
      "    np.random.shuffle(rows) #Randomly shuffle the list of rows in the dataframe\n",
      "    splitNum = round(pruning_proportion * len(rows)) #Find the position in rows that will be closest to the desired proportion\n",
      "    training_rows, pruning_rows = rows[splitNum:], rows[:splitNum] #split the data\n",
      "    return training_rows, pruning_rows\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reload(hl)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "<module 'hybrid_logit' from 'hybrid_logit.py'>"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "orig_design = pd.read_pickle(\"dataframes/design_DF_4Tree.pkl\")\n",
      "data_2012 = pd.read_pickle(\"dataframes/design_DF_4Tree_2012.pkl\")\n",
      "results_col = \"SER_INJ\"\n",
      "\n",
      "sample_sizes = [400, 800, 1200, len(orig_design)]\n",
      "\n",
      "for sample_size in sample_sizes:\n",
      "    err_panel = None\n",
      "    panel_dict = {}\n",
      "    for iteration in range(10):\n",
      "        #Create the overall training set\n",
      "        orig_rows = orig_design.index.tolist() #Get a list of the rows in the original design matrix\n",
      "        np.random.shuffle(orig_rows) #Shuffle the rows\n",
      "        train_rows = orig_rows[:sample_size] #Take the appropriate amount of the list of rows given the sample size\n",
      "        training_set = orig_design.loc[train_rows] #Filter the original design matrix to the selected rows from above\n",
      "        assert len(training_set.groupby(results_col).size()) == 2 #make sure both classes are in the dataframe\n",
      "        \n",
      "        #Separate the data into a training and pruning set for the decision tree building\n",
      "        tree_training_set, tree_pruning_set = hl.split_data(training_set, 0.2)\n",
      "        \n",
      "        decision_tree = treepredict.buildTreePandas(tree_training_set, results_col) #build the decision tree\n",
      "        #Prune the decision tree\n",
      "        pruned_decision_tree = treepredict.prune(decision_tree, tree_pruning_set, results_col, \"reduced_error\")\n",
      "        \n",
      "#        with open(\"trees/pruned_naiveTree_trainingSet_{}.pkl\".format(sample_size), \"wb\") as g:\n",
      "#             cPickle.dump(pruned_decision_tree, g)\n",
      "        tree_nodes = treepredict.fetchNodes(pruned_decision_tree)\n",
      "        if len(tree_nodes) < 2:\n",
      "            print \"=\"*10\n",
      "            sent1 = \"The pruned tree at sample size {}, iteration {}, contained less than two leaf nodes.\".format(sample_size, num)\n",
      "            print  sent1 + \"No logit models were built at this sample size and iteration.\"\n",
      "            print \"=\"*10\n",
      "            continue\n",
      "        node_augmented_2011 = training_set.apply(treepredict.set_node_num, axis = 1, args=(\"nodeNum\", tree_nodes))\n",
      "        \n",
      "        pure_logit_model = hl.make_logit_models(node_augmented_2011, results_col, 'pure', fit_term = 'ncg')\n",
      "        \n",
      "#         with open(\"models_and_errors/pure_logit_{}.pkl\".format(sample_size), \"wb\") as f:\n",
      "#             cPickle.dump(pure_logit_model, f)\n",
      "            \n",
      "        hybrid_logit_model = hl.make_logit_models(node_augmented_2011, results_col, 'hybrid', tree = pruned_decision_tree,\n",
      "                                                  fit_term = 'ncg')\n",
      "        \n",
      "#         with open(\"models_and_errors/naive_model_{}.pkl\".format(sample_size), \"wb\") as f:\n",
      "#             cPickle.dump(hybrid_logit_model, f)\n",
      "        \n",
      "        node_augmented_2012 = data_2012.apply(treepredict.set_node_num, axis = 1, args=(\"nodeNum\", tree_nodes))\n",
      "        \n",
      "        error_comparison = hl.predict_with_hybrid_tree_and_logit(node_augmented_2012, pruned_decision_tree,\n",
      "                                                                 hybrid_logit_model, pure_logit_model,\n",
      "                                                                 results_col, [0, 1])\n",
      "        \n",
      "#         with open(\"models_and_errors/naive_errors_df_{}.pkl\".format(sample_size), \"wb\") as f:\n",
      "#             cPickle.dump(error_comparison, f)    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<p><font size=5 color='brown'>Remaining Work:</font></p>\n",
      "<p>\n",
      "    <ol>\n",
      "        <li>Write in code to calculate the precision points and the recall points for each of the three classifiers.</li>\n",
      "        <li>Write in code to add the precision points and recall points to the main error_comparison dataframe</li>\n",
      "        <li>Write in code to add the copmleted error_comparison dataframe to the panel_dict with the key being the iteration</li>\n",
      "        <li>Write in code to create the panel dataframe from panel_dict</li>\n",
      "        <li>Write in code to save the panel dataframe to file with the file name referencing the training set size in the name</li>\n",
      "        <li>Write in code to create the \"average error dataframes\" from the panel error dataframes</li>\n",
      "        <li>Write in code to construct all the desired graphs from each of the average error dataframes</li>\n",
      "    </ol>\n",
      "</p>\n",
      "        "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open(\"models_and_errors/naive_errors_df_{}.pkl\".format(1142), \"rb\") as f:\n",
      "    error_frame = cPickle.load(f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "error_frame"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Hybrid</th>\n",
        "      <th>Logit</th>\n",
        "      <th>Tree</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>Total Error Rate</th>\n",
        "      <td> 0.219906</td>\n",
        "      <td> 0.217301</td>\n",
        "      <td> 0.210005</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Class 0 Error Rate</th>\n",
        "      <td> 0.055448</td>\n",
        "      <td> 0.041264</td>\n",
        "      <td> 0.031593</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Class 1 Error Rate</th>\n",
        "      <td> 0.913043</td>\n",
        "      <td> 0.959239</td>\n",
        "      <td> 0.961957</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Precision</th>\n",
        "      <td> 0.271186</td>\n",
        "      <td> 0.189873</td>\n",
        "      <td> 0.222222</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Recall</th>\n",
        "      <td> 0.086957</td>\n",
        "      <td> 0.040761</td>\n",
        "      <td> 0.038043</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 3 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "                      Hybrid     Logit      Tree\n",
        "Total Error Rate    0.219906  0.217301  0.210005\n",
        "Class 0 Error Rate  0.055448  0.041264  0.031593\n",
        "Class 1 Error Rate  0.913043  0.959239  0.961957\n",
        "Precision           0.271186  0.189873  0.222222\n",
        "Recall              0.086957  0.040761  0.038043\n",
        "\n",
        "[5 rows x 3 columns]"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t1 = np.random.rand(5)\n",
      "t2 = np.random.rand(5)\n",
      "t3 = np.random.rand(5)\n",
      "t4 = np.random.rand(5)\n",
      "t5 = np.array(range(1,6))\n",
      "t6 = np.array(range(5,0, -1))\n",
      "test1 = pd.DataFrame({\"add1\": [t1, t2, t5]})\n",
      "test2 = pd.DataFrame({\"add1\": [t3, t4, t6]})\n",
      "\n",
      "test_panel = pd.Panel.from_dict({0:test1, 1:test2}, orient='minor')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_add.loc[2] = [np.random.rand(5)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_add"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>add</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> [0.814256690674, 0.522560987564, 0.64693830124...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> [1.24719576565, 1.02062453218, 1.80012820195, ...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> [0.462556077586, 0.48033131408, 0.973551615189...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>3 rows \u00d7 1 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "                                                 add\n",
        "0  [0.814256690674, 0.522560987564, 0.64693830124...\n",
        "1  [1.24719576565, 1.02062453218, 1.80012820195, ...\n",
        "2  [0.462556077586, 0.48033131408, 0.973551615189...\n",
        "\n",
        "[3 rows x 1 columns]"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}